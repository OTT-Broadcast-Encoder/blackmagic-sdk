/* -LICENSE-START-
** Copyright (c) 2023 Blackmagic Design
**  
** Permission is hereby granted, free of charge, to any person or organization 
** obtaining a copy of the software and accompanying documentation (the 
** "Software") to use, reproduce, display, distribute, sub-license, execute, 
** and transmit the Software, and to prepare derivative works of the Software, 
** and to permit third-parties to whom the Software is furnished to do so, in 
** accordance with:
** 
** (1) if the Software is obtained from Blackmagic Design, the End User License 
** Agreement for the Software Development Kit (“EULA”) available at 
** https://www.blackmagicdesign.com/EULA/DeckLinkSDK; or
** 
** (2) if the Software is obtained from any third party, such licensing terms 
** as notified by that third party,
** 
** and all subject to the following:
** 
** (3) the copyright notices in the Software and this entire statement, 
** including the above license grant, this restriction and the following 
** disclaimer, must be included in all copies of the Software, in whole or in 
** part, and all derivative works of the Software, unless such copies or 
** derivative works are solely in the form of machine-executable object code 
** generated by a source language processor.
** 
** (4) THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS 
** OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, 
** FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT 
** SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE 
** FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE, 
** ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER 
** DEALINGS IN THE SOFTWARE.
** 
** A copy of the Software is available free of charge at 
** https://www.blackmagicdesign.com/desktopvideo_sdk under the EULA.
** 
** -LICENSE-END-
*/

#import <CoreFoundation/CFString.h>
#include <array>

#import "SyncController.h"
#import "DeckLinkDeviceDiscovery.h"
#import "DeckLinkOutputDevice.h"

#include "SignalGenerator3DVideoFrame.h"

// SD 75% Colour Bars
static const std::array<uint32_t, 8> gSD75pcColourBars =
{
	0xeb80eb80, 0xa28ea22c, 0x832c839c, 0x703a7048,
	0x54c654b8, 0x41d44164, 0x237223d4, 0x10801080
};

// HD 75% Colour Bars
static const std::array<uint32_t, 8> gHD75pcColourBars =
{
	0xeb80eb80, 0xa888a82c, 0x912c9193, 0x8534853f,
	0x3fcc3fc1, 0x33d4336d, 0x1c781cd4, 0x10801080
};

static const NSDictionary* kPixelFormats = @{
	[NSNumber numberWithInteger:bmdFormat8BitYUV]	: @"8-bit YUV",
	[NSNumber numberWithInteger:bmdFormat10BitYUV]	: @"10-bit YUV",
	[NSNumber numberWithInteger:bmdFormat8BitARGB]	: @"8-bit RGB",
	[NSNumber numberWithInteger:bmdFormat10BitRGB]	: @"10-bit RGB"
};

// Constants for calculating audio tone
static const double kReferenceSoundPressure = 20.0; // dB
static const double kReferenceAudioToneLevel = -20.0; // dB
static const int kReferenceAudioToneFreq = 1000; // Hz

constexpr BOOL PixelFormatIsRGB(BMDPixelFormat pf) { return (pf == bmdFormat8BitARGB) || (pf == bmdFormat10BitRGB); }

class Timecode
{
public:
	Timecode(int f, int d)
	: m_fps(f), m_framecount(0), m_dropframes(d), m_frames(0),m_seconds(0),m_minutes(0),m_hours(0)
	{
	}
	void update()
	{
		unsigned long frameCountNormalized = ++m_framecount;
		
		if (m_dropframes)
		{
			int deciMins, deciMinsRemainder;
			
			int framesIn10mins = (60 * 10 * m_fps) - (9 * m_dropframes);
			deciMins = (int)(frameCountNormalized / framesIn10mins);
			deciMinsRemainder = (int)(frameCountNormalized - (deciMins * framesIn10mins));
			
			// Add drop frames for 9 minutes of every 10 minutes that have elapsed
			// AND drop frames for every minute (over the first minute) in this 10-minute block.
			frameCountNormalized += m_dropframes * 9 * deciMins;
			if (deciMinsRemainder >= m_dropframes)
				frameCountNormalized += m_dropframes * ((deciMinsRemainder - m_dropframes) / (framesIn10mins / 10));
		}
		
		m_frames = (int)(frameCountNormalized % m_fps);
		frameCountNormalized /= m_fps;
		m_seconds = (int)(frameCountNormalized % 60);
		frameCountNormalized /= 60;
		m_minutes = (int)(frameCountNormalized % 60);
		frameCountNormalized /= 60;
		m_hours = (int)frameCountNormalized;
	}
	int hours() const { return m_hours; }
	int minutes() const { return m_minutes; }
	int seconds() const { return m_seconds; }
	int frames() const { return m_frames; }
	unsigned long frameCount() const { return m_framecount; }
private:
	int m_fps;
	unsigned long m_framecount;
	int m_dropframes;
	int m_frames;
	int m_seconds;
	int m_minutes;
	int m_hours;
};

void	fillSine (uint8_t* audioBuffer, uint32_t samplesToWrite, uint32_t channels, uint32_t sampleDepth);
void	fillColourBars (com_ptr<IDeckLinkMutableVideoFrame>& theFrame, BOOL reversed);
void	fillBlack (com_ptr<IDeckLinkMutableVideoFrame>& theFrame, BOOL);
int		getRowBytes(BMDPixelFormat pixelFormat, int frameWidth);


@implementation SyncController

@synthesize window;

- (void)addDevice:(const com_ptr<IDeckLink>&)deckLink
{
	// Create new DeckLinkOutputDevice object to wrap around new IDeckLink instance
	DeckLinkOutputDevice* device = [[DeckLinkOutputDevice alloc] initWithDeckLink:deckLink syncController:self];

	if (device == nil)
	{
		[self showErrorMessage:@"Error initialising the new device"
			   informativeText:@"This application is unable to initialise the new device\nAre you using a capture-only device (eg UltraStudio Mini Recorder)?"];
		return;
	}

	[[deviceListPopup menu] addItemWithTitle:(NSString*)[device deviceName] action:nil keyEquivalent:@""];
	[[deviceListPopup lastItem] setTag:(NSInteger)device];
	[[deviceListPopup lastItem] setEnabled:device.isActive];

	if ([deviceListPopup numberOfItems] == 1)
	{
		// We have added our first item, enable the interface
		[deviceListPopup selectItemAtIndex:0];
		[self newDeviceSelected:nil];
		[self enableInterface:YES];
	}
}

- (void)removeDevice:(const com_ptr<IDeckLink>&)deckLink
{
	DeckLinkOutputDevice* deviceToRemove = nil;
	DeckLinkOutputDevice* removalCandidate = nil;
	NSInteger index = 0;

	// Find the DeckLinkDevice that wraps the IDeckLink being removed
	for (NSMenuItem* item in [deviceListPopup itemArray])
	{
		removalCandidate = (DeckLinkOutputDevice*)[item tag];
		
		if ([removalCandidate deckLink] == deckLink)
		{
			deviceToRemove = removalCandidate;
			break;
		}
		++index;
	}

	if (deviceToRemove == nil)
		return;

	// If playback is ongoing, stop it
	if ( (selectedDevice == deviceToRemove) && (running == YES) )
		[self stopRunning];

	[deviceListPopup removeItemAtIndex:index];

	if ([deviceListPopup numberOfItems] == 0)
	{
		// We have removed the last item, disable the interface
		[startButton setEnabled:NO];
		[self enableInterface:NO];
		selectedDevice = nil;
	}
	else if (selectedDevice == deviceToRemove)
	{
		// Select the first device in the list and enable the interface
		[deviceListPopup selectItemAtIndex:0];
		[self newDeviceSelected:nil];
	}

	// Release DeckLinkDevice instance
	[deviceToRemove release];
}

- (void)refreshDisplayModeMenu
{
	// Populate the display mode menu with a list of display modes supported by the installed DeckLink card
	[videoFormatPopup removeAllItems];

	[selectedDevice queryDisplayModesWithBlock:(^(BMDDisplayMode displayMode, NSString* displayModeString) {
		// Add this item to the video format poup menu
		[videoFormatPopup addItemWithTitle:displayModeString];

		// Save the BMDDisplayMode in the menu item's tag
		[[videoFormatPopup lastItem] setTag:(NSInteger)displayMode];
		
		if ([videoFormatPopup numberOfItems] == 1)
		{
			// We have added our first item, refresh pixel formats
			[videoFormatPopup selectItemAtIndex:0];
			[self newDisplayModeSelected:nil];
		}
		
		// Check Dual Stream 3D support with any pixel format
		bool supported;
		HRESULT hr = [selectedDevice deckLinkOutput]->DoesSupportVideoMode(bmdVideoConnectionUnspecified,
																		   displayMode,
																		   bmdFormatUnspecified,
																		   bmdNoVideoOutputConversion,
																		   bmdSupportedVideoModeDualStream3D,
																		   nullptr,
																		   &supported);
		if (hr != S_OK || !supported)
			return;

		NSString* modeName3D = [NSString stringWithFormat:@"%@ 3D", displayModeString];
		[videoFormatPopup addItemWithTitle:modeName3D];
		[[videoFormatPopup lastItem] setTag:(NSInteger)displayMode];
	})];
	
	[startButton setEnabled:([videoFormatPopup numberOfItems] != 0)];
}

- (void)refreshPixelFormatMenu
{
	// Populate the pixel format menu with a list of pixel formats supported with selected display mode
	com_ptr<IDeckLinkOutput> deckLinkOutput = [selectedDevice deckLinkOutput];
	
	[pixelFormatPopup removeAllItems];
	
	for (NSNumber* key in kPixelFormats)
	{
		BMDPixelFormat				pixelFormat;
		BMDSupportedVideoModeFlags	videoModeFlags = bmdSupportedVideoModeDefault;
		bool						supported;
		HRESULT						hr;
		
		pixelFormat = (BMDPixelFormat)[key intValue];
		
		if ((selectedVideoOutputFlags & bmdVideoOutputDualStream3D) != 0)
			videoModeFlags = bmdSupportedVideoModeDualStream3D;

		hr = deckLinkOutput->DoesSupportVideoMode(bmdVideoConnectionUnspecified, selectedDisplayMode, pixelFormat, bmdNoVideoOutputConversion, videoModeFlags, nullptr, &supported);
		if (hr != S_OK || ! supported)
			continue;

		[pixelFormatPopup addItemWithTitle:kPixelFormats[key]];
		[[pixelFormatPopup lastItem] setTag:(NSInteger)pixelFormat];
	}
}

- (void)refreshAudioChannelMenu
{
	int64_t					maxAudioChannels;
	NSMenuItem*				audioChannelPopupItem;
	int						audioChannelSelected;
	int						currentAudioChannel;

	audioChannelSelected = (int)[[audioChannelPopup selectedItem] tag];

	maxAudioChannels = [selectedDevice maximumAudioChannels];
	
	// Scan through Audio channel popup menu and disable invalid entries
	for (int i = 0; i < [audioChannelPopup numberOfItems]; i++)
	{
		audioChannelPopupItem = [audioChannelPopup itemAtIndex:i];
		currentAudioChannel = (int)[audioChannelPopupItem tag];
		
		if (maxAudioChannels >= (int64_t) currentAudioChannel)
		{
			[audioChannelPopupItem setHidden:NO];
			if (audioChannelSelected >= currentAudioChannel)
				[audioChannelPopup selectItemAtIndex:i];
		}
		else
			[audioChannelPopupItem setHidden:YES];
	}
}

- (IBAction)newDeviceSelected:(id)sender
{
	// Get the DeckLinkDevice object for the selected menu item.
	selectedDevice = (DeckLinkOutputDevice*)[[deviceListPopup selectedItem] tag];
	
	// Update the display mode popup menu
	[self refreshDisplayModeMenu];

	// Set Screen Preview callback for selected device
	com_ptr<IDeckLinkOutput> deckLinkOutput = [selectedDevice deckLinkOutput];
	deckLinkOutput->SetScreenPreviewCallback(CreateCocoaScreenPreview(previewView));
	
	// Check whether HFRTC is supported by the selected device
	hfrtcSupported = [selectedDevice supportsHFRTimecode];
	
	// Update available audio channels
	[self refreshAudioChannelMenu];

	// Enable the interface
	[self enableInterface:YES];
}

- (IBAction)newDisplayModeSelected:(id)sender
{
	NSMenuItem* videoFormatItem;
	
	selectedVideoOutputFlags = bmdVideoOutputFlagDefault;
	
	// If the mode title contains "3D" then enable the video in 3D mode
	videoFormatItem = [videoFormatPopup selectedItem];
	
	if ([[videoFormatItem title] hasSuffix:(NSString*)CFSTR("3D")])
		selectedVideoOutputFlags |= bmdVideoOutputDualStream3D;

	selectedDisplayMode = (BMDDisplayMode)[videoFormatItem tag];

	if (selectedDisplayMode == bmdModeNTSC ||
		selectedDisplayMode == bmdModeNTSC2398 ||
		selectedDisplayMode == bmdModePAL)
	{
		timeCodeFormat = bmdTimecodeVITC;
		selectedVideoOutputFlags |= bmdVideoOutputVITC;
	}
	else
	{
		timeCodeFormat = bmdTimecodeRP188Any;
		selectedVideoOutputFlags |= bmdVideoOutputRP188;
	}
	
	[self refreshPixelFormatMenu];
}


- (com_ptr<SignalGenerator3DVideoFrame>)CreateOutputFrame:(FillFrameFunction)fillFrame
{
	com_ptr<IDeckLinkOutput>				deckLinkOutput = [selectedDevice deckLinkOutput];
	com_ptr<IDeckLinkMutableVideoFrame>		referenceBarsLeft;
	com_ptr<IDeckLinkMutableVideoFrame>		referenceBarsRight;
	com_ptr<IDeckLinkMutableVideoFrame>		scheduleBarsLeft;
	com_ptr<IDeckLinkMutableVideoFrame>		scheduleBarsRight;
	HRESULT									hr;
	BMDPixelFormat							pixelFormat;
	int										bytesPerRow;
	com_ptr<IDeckLinkVideoConversion>		frameConverter;
	com_ptr<SignalGenerator3DVideoFrame>	ret;

	pixelFormat = (BMDPixelFormat)[[pixelFormatPopup selectedItem] tag];
	bytesPerRow = getRowBytes(pixelFormat, frameWidth);

	frameConverter = CreateVideoConversionInstance();
	if (frameConverter == nullptr)
		return nullptr;
	
	// Request a left and right frame from the device
	hr = deckLinkOutput->CreateVideoFrame(frameWidth, frameHeight, bytesPerRow, pixelFormat, bmdFrameFlagDefault, scheduleBarsLeft.releaseAndGetAddressOf());
	if (hr != S_OK)
		return nullptr;

	// 8-bit YUV pixels can be filled directly without conversion
	if (pixelFormat == bmdFormat8BitYUV)
	{
		fillFrame(scheduleBarsLeft, NO);
	}
	else
	{
		// If the pixel formats are different create and fill an 8 bit YUV reference frame
		hr = deckLinkOutput->CreateVideoFrame(frameWidth, frameHeight, frameWidth*2, bmdFormat8BitYUV, bmdFrameFlagDefault, referenceBarsLeft.releaseAndGetAddressOf());
		if (hr != S_OK)
			return nullptr;
		
		fillFrame(referenceBarsLeft, NO);
		
		hr = frameConverter->ConvertFrame(referenceBarsLeft.get(), scheduleBarsLeft.get());
		if (hr != S_OK)
			return nullptr;
	}
	
	if (selectedVideoOutputFlags & bmdVideoOutputDualStream3D)
	{
		// If 3D mode requested, fill right eye with reversed colour bars
		hr = deckLinkOutput->CreateVideoFrame(frameWidth, frameHeight, bytesPerRow, pixelFormat, bmdFrameFlagDefault, scheduleBarsRight.releaseAndGetAddressOf());
		if (hr != S_OK)
			return nullptr;

		// 8-bit YUV pixels can be filled directly without conversion
		if (pixelFormat == bmdFormat8BitYUV)
		{
			fillFrame(scheduleBarsRight, true);
		}
		else
		{
			// If the pixel formats are different create and fill an 8 bit YUV reference frame
			hr = deckLinkOutput->CreateVideoFrame(frameWidth, frameHeight, frameWidth*2, bmdFormat8BitYUV, bmdFrameFlagDefault, referenceBarsRight.releaseAndGetAddressOf());
			if (hr != S_OK)
				return nullptr;

			fillFrame(referenceBarsRight, true);

			hr = frameConverter->ConvertFrame(referenceBarsRight.get(), scheduleBarsRight.get());
			if (hr != S_OK)
				return nullptr;
		}
	}
	
	ret = new SignalGenerator3DVideoFrame(scheduleBarsLeft, scheduleBarsRight);
	return ret;
}

- (void)applicationDidFinishLaunching:(NSNotification*)notification
{
	//
	// Setup UI

	// Empty popup menus
	[deviceListPopup removeAllItems];
	[videoFormatPopup removeAllItems];

	// Set device list popup for manual enabling, so we can disable inactive devices
	[deviceListPopup setAutoenablesItems:NO];
	
	// Disable the interface
	[startButton setEnabled:NO];
	[self enableInterface:NO];

	//
	// Create and initialise DeckLink device discovery and profile callback objects
	deckLinkDiscovery = [[DeckLinkDeviceDiscovery alloc] initWithSyncController:self];
	if (deckLinkDiscovery != nil)
	{
		[deckLinkDiscovery enable];
	}
	else
	{
		[self showErrorMessage:@"This application requires the Desktop Video drivers installed."
			   informativeText:@"Please install the Blackmagic Desktop Video drivers to use the features of this application."];

	}
}

- (void)enableInterface:(BOOL)enable
{
	// Set the enable state of user interface elements
	[deviceListPopup setEnabled:enable];
	[outputSignalPopup setEnabled:enable];
	[audioChannelPopup setEnabled:enable];
	[audioSampleDepthPopup setEnabled:enable];
	[videoFormatPopup setEnabled:enable];
	[pixelFormatPopup setEnabled:enable];
}

- (IBAction)toggleStart:(id)sender
{
	if (running == NO)
		[self startRunning];
	else
		[self stopRunning];
}

- (void)startRunning
{
	com_ptr<IDeckLinkDisplayMode>	displayMode;
	com_ptr<IDeckLinkOutput>		deckLinkOutput = [selectedDevice deckLinkOutput];
	bool							pixelFormatRGB;

	// Determine the audio and video properties for the output stream
	outputSignal = (OutputSignal)[outputSignalPopup indexOfSelectedItem];
	audioChannelCount = (uint32_t)[[audioChannelPopup selectedItem] tag];
	audioSampleDepth = (BMDAudioSampleType)[[audioSampleDepthPopup selectedItem] tag];
	audioSampleRate = bmdAudioSampleRate48kHz;

	if (deckLinkOutput->GetDisplayMode(selectedDisplayMode, displayMode.releaseAndGetAddressOf()) != S_OK)
		goto bail;
	
	frameWidth = (int32_t)displayMode->GetWidth();
	frameHeight = (int32_t)displayMode->GetHeight();
	fieldDominance = displayMode->GetFieldDominance();

	displayMode->GetFrameRate(&frameDuration, &frameTimescale);
	// Calculate the number of frames per second, rounded up to the nearest integer.  For example, for NTSC (29.97 FPS), framesPerSecond == 30.
	framesPerSecond = (uint32_t)((frameTimescale + (frameDuration-1)) / frameDuration);

	// Set the preroll to 1/2 second of video frames
	selectedDevice.videoPrerollSize = framesPerSecond / 2;
	selectedDevice.audioWaterLevel = bmdAudioSampleRate48kHz / 2;
	
	// m-rate frame rates with multiple 30-frame counting should implement Drop Frames compensation, refer to SMPTE 12-1
	if (frameDuration == 1001 && frameTimescale % 30000 == 0)
		dropFrames = (uint32_t)(2 * (frameTimescale / 30000));
	else
		dropFrames = 0;
	
	timeCode = std::make_unique<Timecode>(framesPerSecond, dropFrames);
	
	// Set the SDI output to 444 if RGB mode is selected.
	pixelFormatRGB = PixelFormatIsRGB((BMDPixelFormat)[[pixelFormatPopup selectedItem] tag]);
	[selectedDevice setOutput444:pixelFormatRGB];
	
	// Set the video output mode
	if (deckLinkOutput->EnableVideoOutput(selectedDisplayMode, selectedVideoOutputFlags) != S_OK)
		goto bail;
	
	// Set the audio output mode
	if (deckLinkOutput->EnableAudioOutput(bmdAudioSampleRate48kHz, audioSampleDepth, audioChannelCount, bmdAudioOutputStreamTimestamped) != S_OK)
		goto bail;

	// Generate one second of audio tone
	audioSamplesPerFrame = (uint32_t)((audioSampleRate * frameDuration) / frameTimescale);
	audioBufferSampleLength = (uint32_t)((framesPerSecond * audioSampleRate * frameDuration) / frameTimescale);
	audioBuffer.resize(audioBufferSampleLength * audioChannelCount * (audioSampleDepth / 8), 0x0);  // Zero buffer  (interpreted as audio silence)
	audioBufferOffset = 0;
	audioStreamTime = 0;

	if (outputSignal == kOutputSignalPip)
		fillSine(audioBuffer.data(), audioSamplesPerFrame, audioChannelCount, audioSampleDepth);
	else
		fillSine(audioBuffer.data() + (audioSamplesPerFrame * audioChannelCount * audioSampleDepth / 8),
				 (audioBufferSampleLength - audioSamplesPerFrame), audioChannelCount, audioSampleDepth);

	videoFrameBlack = [self CreateOutputFrame:fillBlack];
	if (! videoFrameBlack)
		goto bail;

	videoFrameBars = [self CreateOutputFrame:fillColourBars];
	if (! videoFrameBars)
		goto bail;

	// Begin video preroll by scheduling a second of frames in hardware
	for (int i = 0; i < framesPerSecond; i++)
		[self scheduleNextFrame:YES];
	
	// Begin audio preroll.  This will begin calling our audio callback, which will start the DeckLink output stream.
	if (deckLinkOutput->BeginAudioPreroll() != S_OK)
		goto bail;

	// Success; update the UI
	running = YES;
	[startButton setTitle:@"Stop"];
	// Disable the user interface while running (prevent the user from making changes to the output signal)
	[self enableInterface:NO];
	
	return;
	
bail:
	// *** Error-handling code.  Cleanup any resources that were allocated. *** //
	[self showErrorMessage:@"Unable to start playback."
		   informativeText:@"Could not start playback, is the device already in use?"];
	
	[self stopRunning];
}

- (void)stopRunning
{
	com_ptr<IDeckLinkOutput> deckLinkOutput = [selectedDevice deckLinkOutput];

	// Stop the audio and video output streams immediately
	deckLinkOutput->StopScheduledPlayback(0, NULL, 0);
	
	// DisableVideoOutput will block until all scheduled frames are completed or flushed
	deckLinkOutput->DisableVideoOutput();
	deckLinkOutput->DisableAudioOutput();

	// Success; update the UI
	running = NO;
	[startButton setTitle:@"Start"];
	// Re-enable the user interface when stopped
	[self enableInterface:YES];
}

- (void)scheduleNextFrame:(BOOL)prerolling
{
	HRESULT									result = S_OK;
	com_ptr<IDeckLinkOutput>				deckLinkOutput = [selectedDevice deckLinkOutput];
	com_ptr<SignalGenerator3DVideoFrame>	currentFrame;
	bool									setVITC1Timecode = false;
	bool									setVITC2Timecode = false;
	unsigned long 							totalFramesScheduled = timeCode->frameCount();

	if (prerolling == NO)
	{
		// If not prerolling, make sure that playback is still active
		if (running == NO)
			return;
	}
	
	if (outputSignal == kOutputSignalPip)
	{
		if ((totalFramesScheduled % framesPerSecond) == 0)
		{
			// On each second, schedule a frame of bars
			currentFrame = videoFrameBars;
		}
		else
		{
			// Schedue frames of black
			currentFrame = videoFrameBlack;
		}
	}
	else
	{
		if ((totalFramesScheduled % framesPerSecond) == 0)
		{
			// On each second, schedule a frame of black
			currentFrame = videoFrameBlack;
		}
		else
		{
			// Schedue frames of color bars
			currentFrame = videoFrameBars;
		}
	}

	// Clear old timecodes from frame
	currentFrame->SetTimecode(bmdTimecodeVITC, nullptr);
	currentFrame->SetTimecode(bmdTimecodeRP188VITC1, nullptr);
	currentFrame->SetTimecode(bmdTimecodeRP188VITC2, nullptr);
	currentFrame->SetTimecode(bmdTimecodeRP188HighFrameRate, nullptr);
	
	if (timeCodeFormat == bmdTimecodeVITC)
	{
		result = currentFrame->SetTimecodeFromComponents(bmdTimecodeVITC,
														 timeCode->hours(),
														 timeCode->minutes(),
														 timeCode->seconds(),
														 timeCode->frames(),
														 bmdTimecodeFlagDefault);
		if (result != S_OK)
		{
			fprintf(stderr, "Could not set VITC timecode on frame - result = %08x\n", result);
			goto bail;
		}
	}
	else
	{
		int frames = timeCode->frames();
		
		if (hfrtcSupported)
		{
			result = currentFrame->SetTimecodeFromComponents(bmdTimecodeRP188HighFrameRate,
															 timeCode->hours(),
															 timeCode->minutes(),
															 timeCode->seconds(),
															 frames,
															 bmdTimecodeFlagDefault);
			if (result != S_OK)
			{
				fprintf(stderr, "Could not set HFRTC timecode on frame - result = %08x\n", result);
				goto bail;
			}
		}
		
		if (fieldDominance != bmdProgressiveFrame)
		{
			// An interlaced or PsF frame has both VITC1 and VITC2 set with the same timecode value (SMPTE ST 12-2:2014 7.2)
			setVITC1Timecode = true;
			setVITC2Timecode = true;
		}
		else if (framesPerSecond <= 30)
		{
			// If this isn't a High-P mode, then just use VITC1 (SMPTE ST 12-2:2014 7.2)
			setVITC1Timecode = true;
		}
		else if (framesPerSecond <= 60)
		{
			// If this is a High-P mode then use VITC1 on even frames and VITC2 on odd frames. This is done because the
			// frames field of the RP188 VITC timecode cannot hold values greater than 30 (SMPTE ST 12-2:2014 7.2, 9.2)
			if ((frames & 1) == 0)
				setVITC1Timecode = true;
			else
				setVITC2Timecode = true;
			
			frames >>= 1;
		}
		
		if (setVITC1Timecode)
		{
			result = currentFrame->SetTimecodeFromComponents(bmdTimecodeRP188VITC1,
															 timeCode->hours(),
															 timeCode->minutes(),
															 timeCode->seconds(),
															 frames,
															 bmdTimecodeFlagDefault);
			if (result != S_OK)
			{
				fprintf(stderr, "Could not set VITC1 timecode on interlaced frame - result = %08x\n", result);
				goto bail;
			}
		}
		
		if (setVITC2Timecode)
		{
			// The VITC2 timecode also has the field mark flag set
			result = currentFrame->SetTimecodeFromComponents(bmdTimecodeRP188VITC2,
															 timeCode->hours(),
															 timeCode->minutes(),
															 timeCode->seconds(),
															 frames,
															 bmdTimecodeFieldMark);
			if (result != S_OK)
			{
				fprintf(stderr, "Could not set VITC1 timecode on interlaced frame - result = %08x\n", result);
				goto bail;
			}
		}
	}

	deckLinkOutput->ScheduleVideoFrame(currentFrame.get(), (totalFramesScheduled * frameDuration), frameDuration, frameTimescale);

bail:
	timeCode->update();
}

- (void)writeNextAudioSamples:(uint32_t)samplesToWrite
{
	com_ptr<IDeckLinkOutput>	deckLinkOutput = [selectedDevice deckLinkOutput];
	unsigned int				samplesToEndOfBuffer;
	unsigned int				samplesWritten;

	samplesToEndOfBuffer = (audioBufferSampleLength - audioBufferOffset);
	if (samplesToWrite > samplesToEndOfBuffer)
		samplesToWrite = samplesToEndOfBuffer;

	HRESULT hr = deckLinkOutput->ScheduleAudioSamples((void*)(audioBuffer.data() + audioBufferOffset * audioChannelCount * audioSampleDepth / 8),
													  samplesToWrite, audioStreamTime, audioSampleRate, &samplesWritten);
	if (hr == S_OK)
	{
		audioBufferOffset = ((audioBufferOffset + samplesWritten) % audioBufferSampleLength);
		audioStreamTime += samplesWritten;
	}
}

- (BOOL)applicationShouldTerminateAfterLastWindowClosed:(NSApplication *)theApplication
{
	return YES;
}

- (void)applicationWillTerminate:(NSNotification *)notification
{
	// Stop the output signal
	if (running == YES)
		[self stopRunning];

	// Release all DeckLinkOutputDevice instances
	while([deviceListPopup numberOfItems] > 0)
	{
		DeckLinkOutputDevice* device = (DeckLinkOutputDevice*)[[deviceListPopup itemAtIndex:0] tag];
		if (device != nil)
			[device release];

		[deviceListPopup removeItemAtIndex:0];
	}
	
	// Release DeckLink discovery instance
	if (deckLinkDiscovery != nil)
		[deckLinkDiscovery release];
}

- (void)showErrorMessage:(NSString*)message informativeText:(NSString*)informativeText
{
	NSAlert* alert = [[NSAlert alloc] init];
	alert.messageText = message;
	alert.informativeText = informativeText;
	[alert runModal];
	[alert release];
}

@end

/*****************************************/

void fillSine(uint8_t* audioBuffer, uint32_t samplesToWrite, uint32_t channels, uint32_t sampleDepth)
{
	int audioMaxLevel = (1 << ((int)sampleDepth - 1)) - 1;
	double toneMaxLevel = (double)audioMaxLevel * pow(10.0, kReferenceAudioToneLevel / kReferenceSoundPressure);

	if (sampleDepth == bmdAudioSampleType16bitInteger)
	{
		int16_t* nextBuffer;

		nextBuffer = (int16_t*)audioBuffer;
		for (unsigned i = 0; i < samplesToWrite; i++)
		{
			int16_t sample;

			sample = (int16_t)(toneMaxLevel * sin((i * 2.0 * M_PI * kReferenceAudioToneFreq) / (int)bmdAudioSampleRate48kHz));
			for (unsigned ch = 0; ch < channels; ch++)
				*(nextBuffer++) = sample;
		}
	}
	else if (sampleDepth == bmdAudioSampleType32bitInteger)
	{
		int32_t* nextBuffer;

		nextBuffer = (int32_t*)audioBuffer;
		for (unsigned i = 0; i < samplesToWrite; i++)
		{
			int32_t sample;

			sample = (int32_t)(toneMaxLevel * sin((i * 2.0 * M_PI * kReferenceAudioToneFreq) / (int)bmdAudioSampleRate48kHz));
			for (unsigned ch = 0; ch < channels; ch++)
				*(nextBuffer++) = sample;
		}
	}
}

void fillColourBars(com_ptr<IDeckLinkMutableVideoFrame>& theFrame, BOOL reversed)
{
	uint32_t*		nextWord;
	uint32_t		width;
	uint32_t		height;
	uint8_t			numBars;

	theFrame->GetBytes((void**)&nextWord);
	width = (uint32_t)theFrame->GetWidth();
	height = (uint32_t)theFrame->GetHeight();

	auto& bars = (width > 720) ? gHD75pcColourBars : gSD75pcColourBars;
	numBars = bars.size();

	for (uint32_t y = 0; y < height; y++)
	{
		for (uint32_t x = 0; x < width; x+=2)
		{
			int pos = x * numBars / width;

			if (reversed)
				pos = numBars - pos - 1;

			*(nextWord++) = bars[pos];
		}
	}
}

void fillBlack(com_ptr<IDeckLinkMutableVideoFrame>& theFrame, BOOL /* unused */)
{
	uint32_t*		nextWord;
	uint32_t		width;
	uint32_t		height;
	uint32_t		wordsRemaining;
	
	theFrame->GetBytes((void**)&nextWord);
	width = (uint32_t)theFrame->GetWidth();
	height = (uint32_t)theFrame->GetHeight();

	wordsRemaining = (width*2 * height) / 4;

	while (wordsRemaining-- > 0)
		*(nextWord++) = 0x10801080;
}

int getRowBytes(BMDPixelFormat pixelFormat, int frameWidth)
{
	int bytesPerRow;

	// Refer to DeckLink SDK Manual - 2.7.4 Pixel Formats
	switch (pixelFormat)
	{
		case bmdFormat8BitYUV:
			bytesPerRow = frameWidth * 2;
			break;

		case bmdFormat10BitYUV:
			bytesPerRow = ((frameWidth + 47) / 48) * 128;
			break;

		case bmdFormat10BitRGB:
			bytesPerRow = ((frameWidth + 63) / 64) * 256;
			break;

		case bmdFormat8BitARGB:
		case bmdFormat8BitBGRA:
		default:
			bytesPerRow = frameWidth * 4;
			break;
	}

	return bytesPerRow;
}
